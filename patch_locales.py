"""
Patch script: Add deep analysis i18n keys to existing locale files.

Run once: python patch_locales.py
"""

import json
import os

LOCALES_DIR = os.path.join(os.path.dirname(__file__), "locales")

DEEP_KEYS = {
    "en": {
        "deep": {
            "loading": "üî¨ Running deep analysis... (5-10 sec)",
            "error": "‚ùå Deep analysis failed. Try again later.",
            "days_left": "‚è≥ {days} days remaining",
            "section_probability": "PROBABILITY MODELS",
            "section_edge": "EDGE & SIZING",
            "section_greeks": "TIME & VOLATILITY",
            "section_whale_intel": "WHALE INTELLIGENCE",
            "section_distribution": "SIMULATION DISTRIBUTION",
            "model_vs_market": "model {model}% vs market {market}%",
            "edge_too_small": "Edge too small to bet",
            "no_edge_data": "Insufficient data for edge calculation",
            "theta_anomaly": "Price stuck ‚Äî time decay opportunity!",
            "time_value": "Market overpays {value}¬¢ for uncertainty",
            "vega_sleeping": "Low volatility ‚Äî possible breakout ahead",
            "vega_spiking": "High volatility ‚Äî news event detected!",
            "overreaction": "Market overreaction detected!",
            "no_clear_edge": "No clear edge ‚Äî HOLD / skip",
            "btn_deep": "üî¨ Deep Analysis"
        }
    },
    "uk": {
        "deep": {
            "loading": "üî¨ –ó–∞–ø—É—Å–∫ –≥–ª–∏–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É... (5-10 —Å–µ–∫)",
            "error": "‚ùå –ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É. –°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–∑–Ω—ñ—à–µ.",
            "days_left": "‚è≥ {days} –¥–Ω—ñ–≤ –∑–∞–ª–∏—à–∏–ª–æ—Å—å",
            "section_probability": "–ú–û–î–ï–õ–Ü –ô–ú–û–í–Ü–†–ù–û–°–¢–Ü",
            "section_edge": "EDGE & –†–û–ó–ú–Ü–† –°–¢–ê–í–ö–ò",
            "section_greeks": "–ß–ê–° & –í–û–õ–ê–¢–ò–õ–¨–ù–Ü–°–¢–¨",
            "section_whale_intel": "WHALE INTELLIGENCE",
            "section_distribution": "–†–û–ó–ü–û–î–Ü–õ –°–ò–ú–£–õ–Ø–¶–Ü–ô",
            "model_vs_market": "–º–æ–¥–µ–ª—å {model}% vs —Ä–∏–Ω–æ–∫ {market}%",
            "edge_too_small": "Edge –∑–∞–Ω–∞–¥—Ç–æ –º–∞–ª–∏–π –¥–ª—è —Å—Ç–∞–≤–∫–∏",
            "no_edge_data": "–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É edge",
            "theta_anomaly": "–¶—ñ–Ω–∞ –∑–∞—Å—Ç—Ä—è–≥–ª–∞ ‚Äî –º–æ–∂–ª–∏–≤—ñ—Å—Ç—å –Ω–∞ —á–∞—Å–æ–≤–æ–º—É —Ä–æ–∑–ø–∞–¥—ñ!",
            "time_value": "–†–∏–Ω–æ–∫ –ø–µ—Ä–µ–ø–ª–∞—á—É—î {value}¬¢ –∑–∞ –Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω—ñ—Å—Ç—å",
            "vega_sleeping": "–ù–∏–∑—å–∫–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ñ—Å—Ç—å ‚Äî –º–æ–∂–ª–∏–≤–∏–π —Ä—ñ–∑–∫–∏–π —Ä—É—Ö",
            "vega_spiking": "–í–∏—Å–æ–∫–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω—ñ—Å—Ç—å ‚Äî –Ω–æ–≤–∏–Ω–Ω–∞ –ø–æ–¥—ñ—è!",
            "overreaction": "–í–∏—è–≤–ª–µ–Ω–æ –Ω–∞–¥–º—ñ—Ä–Ω—É —Ä–µ–∞–∫—Ü—ñ—é —Ä–∏–Ω–∫—É!",
            "no_clear_edge": "–ù–µ–º–∞—î —á—ñ—Ç–∫–æ–≥–æ edge ‚Äî HOLD / –ø—Ä–æ–ø—É—Å—Ç–∏—Ç–∏",
            "btn_deep": "üî¨ –ì–ª–∏–±–æ–∫–∏–π –∞–Ω–∞–ª—ñ–∑"
        }
    },
    "ru": {
        "deep": {
            "loading": "üî¨ –ó–∞–ø—É—Å–∫ –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞... (5-10 —Å–µ–∫)",
            "error": "‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.",
            "days_left": "‚è≥ {days} –¥–Ω–µ–π –æ—Å—Ç–∞–ª–æ—Å—å",
            "section_probability": "–ú–û–î–ï–õ–ò –í–ï–†–û–Ø–¢–ù–û–°–¢–ò",
            "section_edge": "EDGE & –†–ê–ó–ú–ï–† –°–¢–ê–í–ö–ò",
            "section_greeks": "–í–†–ï–ú–Ø & –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–¨",
            "section_whale_intel": "WHALE INTELLIGENCE",
            "section_distribution": "–†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–ò–ú–£–õ–Ø–¶–ò–ô",
            "model_vs_market": "–º–æ–¥–µ–ª—å {model}% vs —Ä—ã–Ω–æ–∫ {market}%",
            "edge_too_small": "Edge —Å–ª–∏—à–∫–æ–º –º–∞–ª –¥–ª—è —Å—Ç–∞–≤–∫–∏",
            "no_edge_data": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ edge",
            "theta_anomaly": "–¶–µ–Ω–∞ –∑–∞—Å—Ç—Ä—è–ª–∞ ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–º —Ä–∞—Å–ø–∞–¥–µ!",
            "time_value": "–†—ã–Ω–æ–∫ –ø–µ—Ä–µ–ø–ª–∞—á–∏–≤–∞–µ—Ç {value}¬¢ –∑–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å",
            "vega_sleeping": "–ù–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å ‚Äî –≤–æ–∑–º–æ–∂–µ–Ω —Ä–µ–∑–∫–∏–π —Ä—ã–≤–æ–∫",
            "vega_spiking": "–í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å ‚Äî –Ω–æ–≤–æ—Å—Ç–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ!",
            "overreaction": "–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —á—Ä–µ–∑–º–µ—Ä–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è —Ä—ã–Ω–∫–∞!",
            "no_clear_edge": "–ù–µ—Ç —á—ë—Ç–∫–æ–≥–æ edge ‚Äî HOLD / –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å",
            "btn_deep": "üî¨ –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑"
        }
    }
}


def patch():
    for lang, keys in DEEP_KEYS.items():
        filepath = os.path.join(LOCALES_DIR, f"{lang}.json")
        if not os.path.exists(filepath):
            print(f"SKIP: {filepath} not found")
            continue

        with open(filepath, "r", encoding="utf-8") as f:
            data = json.load(f)

        # Merge deep keys
        for section, values in keys.items():
            if section not in data:
                data[section] = {}
            if isinstance(values, dict):
                data[section].update(values)
            else:
                data[section] = values

        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"PATCHED: {filepath} (+{sum(len(v) if isinstance(v, dict) else 1 for v in keys.values())} keys)")


if __name__ == "__main__":
    patch()
